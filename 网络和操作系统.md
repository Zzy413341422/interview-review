# 计算机网络

## HTTP协议是什么

HTTP协议是超文本传输协议,是用于从万维网服务器传输超文本到本地浏览器的传送协议，是一种规范。

## HTTP是一个基于TCP/IP通信协议来传递数据

![âhttpæ¥ææ ¼å¼âçå¾çæç´¢ç»æ](https://cdn.ru23.com/img/2018/12/http-message2.jpg)

## HTTPS和HTTP的区别

Https是身披SSL(Secure Socket Layer)外壳的Http，运行于SSL上，SSL运行于TCP之上，是添加了加密和认证机制的HTTP。二者之间存在如下不同：
端口不同：Http与Https使用不同的连接方式，用的端口也不一样，前者是80，后者是443；
资源消耗：和HTTP通信相比，Https通信会由于加减密处理消耗更多的CPU和内存资源；
开销：Https通信需要证书，而证书一般需要向认证机构购买； 

## SSL原理

![img](https://user-gold-cdn.xitu.io/2018/1/5/160c5b10d3f27e00?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## HTTP1.0和HTTP1.1和HTTP2.0区别

HTTP1.0：expire

HTTP1.1：Connection:keep-alive、cache-control

HTTP2.0：     1.头部压缩，用二进制替换文本；

![img](https://upload-images.jianshu.io/upload_images/5281821-5e2e23de6cbbc698.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/607/format/webp)

​			2.HTTP/2是完全多路复用的
​			3.服务器推送：还没有收到浏览器的请求，服务器就把各种资源推送给浏览器。

## Http缓存

强制缓存：收到请求，看是否有缓存，然后向服务器询问缓存是否可用，直接使用缓存。

对比缓存：收到请求，看是否有缓存，然后向服务器询问缓存是否可用，可用则返回304；如果不匹配，表示资源有更新，服务器会将新数据和新的缓存标识一起返回到浏览器

**Cache-Control**
Cache-Control 是最重要的规则。常见的取值有private、public、no-cache、max-age，no-store，默认为private。
private:             客户端可以缓存
public:              客户端和代理服务器都可缓存（前端的同学，可以认为public和private是一样的）
max-age=xxx:   缓存的内容将在 xxx 秒后失效
no-cache:          需要使用对比缓存来验证缓存数据（后面介绍）

## HTTP请求的GET方法和POST方法的区别？

GET与POST是我们常用的两种HTTP Method，二者之间的区别:
(1). 从功能上讲，GET一般用来从服务器上获取资源，POST一般用来更新服务器上的资源；
(2). 从请求参数形式上看，GET请求的数据会附在URL之后，以?分割URL和传输数据，参数之间以&相连。
(3). 就安全性而言，POST的安全性要比GET的安全性高，因为GET请求提交的数据将明文出现在URL上，而且POST请求参数则被包装到请求体中，相对更安全。
(4). 从请求的大小看，GET请求的长度受限于浏览器或服务器对URL长度的限制，允许发送的数据量比较小，而POST请求则是没有大小限制的。

## 转发和重定向的区别：

1、浏览器URL的地址栏不变。重定向：浏览器URL的地址栏改变；
2、转发是服务器行为，重定向是客户端行为；
3、转发是浏览器只做了一次访问请求。重定向是浏览器做了至少两次的访问请求的；
4、转发2次跳转之间传输的信息不会丢失，重定向2次跳转之间传输的信息会丢失（request范围）。

## HTTP无状态？session和cookie怎么实现的

HTTP无状态协议，是指协议对事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传。
Cookie和Session都是客户端与服务器之间保持状态的解决方案，cookie是在http请求头的cookie字段中，而session保存在服务端。

## session和cookie的区别

1、session 在服务器端，cookie 在客户端
2、Session的实现常常依赖于Cookie机制，若浏览器禁用Cookie的话，可以通过 URL重写机制将sessionid传回服务器。
3、Cookie有大小限制，Session没有大小限制。
4、Cookie存在安全隐患，通过拦截或本地文件找得到cookie后可以进行攻击，而Session用于保存在服务器端，相对更加安全；

## 常见状态码及原因短语

100：客户端询问是否可以在后续的请求中发送附件
200：服务器已成功处理了请求。 204:表示服务器接收到的请求已经处理完毕，但是服务器不需要返回响应体.
300：提供操作列表供请求者选择 301 : 永久性转移 302 ：暂时性转移（这2个重定向） 304 ：页面已缓存
400：语法错误 	403：拒绝请求  404：客户端所访问的页面不存在 
500 ：服务器内部错误       502：错误网关    503 ： 服务不可用，稍等	504：网关超时

## TCP\UDP的区别

TCP是面向连接的，UDP是无连接的；
TCP是可靠的，UDP是不可靠的；
TCP只支持点对点通信，UDP支持一对一、一对多、多对多的通信模式；
TCP是面向字节流的，UDP是面向报文的；

## 对于可靠性，TCP通过以下方式进行保证：

##### 数据包校验：

目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据；

##### 对失序数据包重排序：

既然TCP报文段作为IP数据报来传输，而IP数据报的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层；

##### 丢弃重复数据：

对于重复数据，能够丢弃重复数据；

##### 应答机制：

当TCP收到发自TCP连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；

##### 超时重发：

当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；

##### 流量控制：

TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。 

![img](https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg)

## UDP实现TCP可靠传输

1. 添加seq/ack机制，实现应答机制
2. 添加发送和接收缓冲区，实现流量控制
3. 设置定时器，实现超时重传机制

## UDP信息传递的方式

单播(unicast):
组播:
广播:广播比较好理解，我这里的局域网网络地址是 192.168.168.0，所以 ip 为 192.168.168.1 - 192.168.168.254 是一个本局域网内的有效 ip 地址192.168.168.255 被称为广播地址，只要给广播地址发消息，该局域网内的所有人都能收到。

## TCP的粘包和UDP的丢包

### TCP粘包

现象：**TCP粘包**是指发送方发送的若干包数据到接收方接收时粘成一包

#### 粘包原因

发送端：发送前收集多个小分组，在一个确认到来时一起发送。

接收端：TCP将收到的分组保存至接收缓存里，多个包就会被存至缓存，应用程序读时，就会读到多个首尾相接粘到一起的包。

#### 粘包处理

加入发送长度

设置定长信息

### UDP丢包

现象：由于不可靠连接方式，数据包可能会在接受过程中丢失一部分。

#### UDP丢包原因

发送端：发送的包太大导致send方法无法正常切割为小包导致丢包、发送的包太大超过缓存设置也会出现对包、发送频率太快导致接收端未接受或溢出缓冲区而丢包。
接收端：处理时间过长导致丢包。
其他：网络等问题。

#### UDP丢包处理

## 网线断了TCP连接情况

处于半连接状态；客户端发送心跳包多次收不到服务器的响应时可终止此TCP连接，而服务端可监测客户端的心跳包，若在一定时间间隔内未收到任何来自客户端的心跳包则可以终止此TCP连接。

## ARQ停止等待协议

发送方每发送一帧就暂停，等待应答（ACK）到来。收方收到数据帧后发送应答（ACK）帧给发送方，发送方再发送下一个数据帧。

## 连续ARQ协议

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。
缺点： 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。

## 地址解析协议 ARP

**ARP用于实现从 IP 地址到 MAC 地址的映射，即询问目标IP对应的MAC地址**。

工作流程：通信时必须要有mac地址，在syn报文到达网络层时，进行一次ARP请求和回复过程，然后封装mac到报文中，且缓存起来。

## 拥塞控制

TCP的拥塞控制采用了四种算法，即 慢开始 、拥塞避免 、快重传 和 快恢复。

送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。只要发送方判断网络出现拥塞，就把慢开始门限设置为出现拥塞时的发送窗口大小的一半。

快重传：没收到确认，连续发送3个回去；快恢复：拥塞窗口大小减半

## OSI参考模型的分为哪几层，每层的功能？

![äºå±ä½ç³»ç»æ](https://camo.githubusercontent.com/5bf7c14046570425f50bca412a3cf3710514ccff/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392f372f2545342542412539342545352542312538322545342542442539332545372542332542422545372542422539332545362539452538342e706e67)

网络层ICMP、网络接口层ARP

## 在浏览器中输入网址到显示出页面的整个过程？

(1) 输出包含域名的网址 (2) 浏览器向DNS请求解析域名对应的IP地址 (3) 域名系统DNS解析出域名对应的IP地址 (4) 浏览器与该服务器建立TCP连接 (5) 浏览器发送HTTP请求 (6) 服务器通过HTTP响应把页面文件发送给浏览器 (7) TCP连接释放 (8) 浏览器解释文件，并显示

## ping指令的整个过程

ping通知系统建立一个固定格式的ICMP请求数据包，根据ip地址获取对方mac地址，若本机无缓存，则进行一次ARP请求和回复过程，然后封装mac到报文中，机器B收到这个数据帧后，先检查目的地址，和本机MAC地址对比符合，接收。

## DNS 解析

浏览器缓存、本地缓存

本地DNS服务器（递归）、根域名服务器、顶级域名服务器、域名服务器（迭代）

递归查询：在该模式下DNS 服务器接收到客户机请求，必须使用一个准确的查询结果回复客户机。

迭代查询：DNS 服务器并不直接回复查询结果，而是告诉客户机另一台DNS 服务器地址，客户机再向这台DNS 服务器提交请求

## http协议与tcp/ip协议有什么区别？http三次握手画图说明。

​	IP想象成一种高速公路，它允许其它协议在上面行驶并找到其它电脑的出口。TCP和UDP是高速公路上的“卡车”，它们携带的货物就是像HTTP，文件传输协议FTP这样的协议等

![ä¸æ¬¡æ¡æ](https://img-blog.csdn.net/20170605110405666?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXpjc3U=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![åæ¬¡æ¥æ](https://img-blog.csdn.net/20170606084851272?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXpjc3U=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 为什么连接的时候是三次握手，关闭的时候却是四次握手？

首先，TCP是可靠的，TCP 的可靠连接是靠序号来达成的。假如只有两次握手，只有服务器对客户端的序号做了确认，但客户端却没有对服务器的序号做确认，不能保证传输的可靠性。

关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。

## 你刚刚说了4次挥手，time_wait和close_wait有什么区别？

Server进入CLOSE_WAIT状态。此时TCP链接处于半关闭状态，即客户端已经没有要发送的数据了，但服务端若发送数据，则客户端仍要接收。
TIME_WAIT 是主动关闭链接时形成的, 主要是防止最后一个ACK丢失

## 为什么是2msl？（报文最大生存时间）

如果客户端不等待2MSL直接进行关闭，前一次的连接的数据还在网络中

## IP地址分类，子网划分（笔试常用）

https://blog.csdn.net/binggetong/article/details/52729175

## DDOS攻击

原因：客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认

预防：限制同时打开SYN半链接的数目；缩短SYN半链接的Time out 时间

## SQL注入

原因：SQL注入就是通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。

预防：对sql语句预编译，使用正则表达式过滤传入的参数

## XSS攻击

原因：用 <script type="text/javascript"></script> 包起来发送的回帖中

预防：正则表达式过滤，将script关键字获取到；

## CSRF攻击

通过xss创建一个自动提交的表格，冒充用户进行一些操作。

预防：请求头加token字段

# 操作系统

## 操作系统的四个特性

并发，共享，虚拟，异步

## 上下文切换

上下文切换(Context Switch)是一种将CPU资源从一个线程分配给另一个线程的机制。

## 守护、僵尸、孤儿进程的概念

守护进程：守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。
僵尸进程：僵尸进程是当子进程比父进程先结束，而父进程又没有回收子进程，释放子进程占用的资源，此时子进程将成为一个僵尸进程。
孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，这些子进程称为孤儿进程。

## 请分别简单说一说进程和线程以及它们的区别。

进程是对运行时程序的封装，是系统进行资源调度和分配的基本单位，实现了操作系统的并发；
线程是进程的子任务，是CPU调度和分配的基本单位，实现进程内部的并发；
一个程序至少有一个进程，一个进程至少有一个线程，线程依赖于进程而存在；
进程拥有独立的内存单元，而多个线程共享进程的内存。

## 线程同步的方式有哪些？

互斥 Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问
信号量 Semphare：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作

## 进程同步

1. 临界区
2. 同步与互斥
3. 信号量
4. 管程（类似Synchronized）

## 进程间的通信的几种方式

管道（pipe）及命名管道（named pipe）：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信；

信号（signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；

消息队列：消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；

共享内存：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等；

信号量：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段；

套接字：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。

## 线程有几种状态？进程有哪几种状态？

就绪状态，运行状态，阻塞状态
创建、就绪、运行、阻塞、等待、时间等待和消亡。

## 进程调度算法

### 批处理系统（人数比较少）

先来先服务：有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行

短作业优先 ：如果一直有短作业到来，那么长作业永远得不到调度。

最短剩余时间优先 ：任务剩余时间越短，则不管长短作业，先执行。

### 交互式系统（人数比较多）

时间片轮转：进程可以执行一个时间片，当时间片用完时，将它送往就绪队列的末尾。

优先级调度：为每个进程分配一个优先级，按优先级进行调度。

多级反馈队列：多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。

## 操作系统页置换的算法

FIFO先进先出算法：在操作系统中经常被用到，比如作业调度（主要实现简单，很容易想到）；
LRU（Least recently use）最近最少使用算法：根据使用时间到现在的长短来判断；
LFU（Least frequently use）最少使用次数算法：根据使用次数来判断；
OPT（Optimal replacement）最优置换算法：理论的最优，理论；就是要保证置换出去的是不再被使用的页，或者是在实际内存中最晚使用的算法

## 磁盘调度算法

先来先服务：按照磁盘请求的顺序进行调度。

最短寻道时间优先：优先调度与当前磁头所在磁道距离最近的磁道。

电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

## 操作系统的虚拟内存

在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。虚拟内存就是在硬盘上面划分出一个区域来充当内存,和物理内存共同来处理信息。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序。

## 操作系统的用户态和核心态切换条件以及为什么要切换

当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。

## 分段和分页有什么区别（内存管理）？

段是信息的逻辑单位，每个段含有一组意义完整的信息，是出于用户角度提出的内存管理机制；页是信息的物理单位，是出于系统内存利用率的角度提出的离散分配机制
页的大小是固定的，由系统决定；段的大小是不确定的，由用户决定。

## 死锁的概念:

两个或多个线程无限期的阻塞、相互等待的一种状态。

” Jconsole查看死锁“

死锁原因： 
竞争资源：请求同一有限资源的进程数多于可用资源数
进程推进顺序非法：进程执行中，请求和释放资源顺序不合理，如资源等待链

## 死锁产生的必要条件：

互斥：至少有一个资源必须属于非共享模式，即一次只能被一个进程使用；
占有并等待：一个进程必须占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有；
非抢占：进程不能被抢占，即资源只能被进程在完成任务后自愿释放
循环等待：若干进程之间形成一种头尾相接的环形等待资源关系

## 死锁处理：

预防死锁：破坏产生死锁的4个必要条件中的一个或者多个；
避免死锁：在资源的动态分配中，防止系统进入可能产生死锁的状态-如银行家算法
检测死锁：允许系统运行过程中产生死锁，在死锁发生之后，采用一定的算法进行检测，并确定与死锁相关的资源和进程
解除死锁：与死锁检测配合，将系统从死锁中解脱出来（撤销进程或者剥夺资源）。

## 经典的线程同步问题（哲学家，生产消费）

生产者消费者问题
哲学家进餐问题
银行家算法`