# Mysql

## Mysql基本架构

![img](md\27.jpg)

查询缓存：mysql8.0后弃用；命中率低且更新字段后大规模失效

连接器：跟客户端建立链接、获取权限、维持和管理连接。

分析器：语法分析会判断你sql的对错

优化器：优化有一步就是要确认使用哪个索引，比如使用你的主键索引，联合索引还是什么索引更好；对执行顺序进行优化，条件那么多，先查哪个表，还是先关联，会出现很多方案，最后由优化器决定选用哪种方案。

执行器：查表

##  ON、WHERE、HAVING的区别

ON、WHERE、HAVING的主要差别是其子句中限制条件起作用时机引起的，ON是在生产临时表之前根据条件筛选记录，WHERE是从生产的临时表中筛选数据，而HAVING是对临时表中满足条件的数据，进行计算分组之后，通过HAVING限制语句筛选分组，返回结果是满足HAVING子句限制的分组。

## 为什么要创建索引

索引是对数据库表中一个或多个列的值进行排序的数据结构，以协助快速查询、更新数据库表中数据。

## 索引的种类：

唯一索引	不允许任何两行具相同值
主键索引	唯一索引的一种
普通索引	无限制
全文索引	针对较大的数据生成全文索引很耗时间空间

## 增加索引也有许多不利的一个方面:

时间方面：创建索引和维护索引要耗费时间
空间方面：索引需要占物理空间。

## 索引有哪些？聚集索引和非聚集索引的区别？

FULLTEXT，HASH，BTREE，RTREE。

- 聚集索引就是以**主键**创建的索引
- 非聚集索引就是以**非主键**创建的索引

区别：

- 聚集索引在叶子节点存储的是**表中的数据**
- 非聚集索引在叶子节点存储的是**主键和索引列**
- 使用非聚集索引查询出数据时，**拿到叶子上的主键再去查到想要查找的数据**。(拿到主键再查找这个过程叫做**回表**)

## 索引规则

![å¾çæè¿°](md\28.png)

遇到范围查询(>、<、between、like、order by)就停止匹配

前导模糊查询不会使用索引：like '%李'

or左右都要有索引

负向条件（!=、<>、not in、not exists、not lik）不会使用索引，建议用in

## 为什么说B+-tree比B 树更适合实际应用中操作系统的文件索引和数据库索引？

![img](md\29.png)

B+tree的磁盘读写代价低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小；
B+tree的查询效率更加稳定；
B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可；

## 什么样的字段适合建索引

唯一、不为空、经常被查询，重复字段少的字段

## 什么情况下不宜建立索引？

对于查询中很少涉及的列或者重复值比较多的列，不宜建立索引。

## 几种数据库对比

![](C:\Users\jimmiezeng\IdeaProjects\interview-review\md\83.png)

es分页处理十分十分慢！

## 数据库引擎有哪些？InnoDB和MyIsam有啥区别?

MyISAM InnoDB MEMORY MERGE BDB；
MyISAM是非事务安全型的，而InnoDB是事务安全型的，
MyISAM锁的粒度是表级，而InnoDB支持行级锁定。
MyISAM相对简单，所以在效率上要优于InnoDB
MyISAM不支持外健，InnoDB支持。

## mysql实现事务的原理

通过redo 和 undo 日志文件实现的
undo记录了数据在事务开始之前的值
redo日志记录数据修改后的值

## 数据库的事务特性

原子性	一致性	隔离性	持久性

## 事务隔离级别

 1. 读未提交（Read Uncommitted）
    
    原理：任何操作都不加锁
    
 2. 读提交（Read Commit）

    原理：MVCC+快照读：每次select都生成一个快照读。因此会产生不可重复读

3. 可重复读（Reapable Read）

   原理：MVCC+快照读：开启事务执行第一个select的时候快照读，生成的快照是通过mvcc和undolog日志来实现的。

4. 串行化（Serializable）

   原理：读写锁或者Next-Key Lock

脏读：一个事务读取了另一个事务未提交的数据；
不可重复读：不可重复读的重点是修改，同样条件下两次读取结果不同，也就是说，被读取的数据可以被其它事务修改；
幻读：幻读的重点在于新增或者删除，同样条件下两次读出来的记录数不一样。

## 当前读的实现方式：next-key锁(行记录锁+Gap间隙锁)

next-key locks由record locks(索引加锁) 和 gap locks

**间隙锁：**只有在Read Repeatable、Serializable隔离级别才有，就是锁定那些范围空间内的数据，假设锁定id>3的数据，id有3,4,5，那么4，5和后面的数字都会被锁定，像6,7…，为什么要这样？因为如果我们不锁定没有的数据，当加入了新的数据id=6，就会出现幻读，间隙锁避免了幻读。

对主键或唯一索引，如果select查询时where条件全部精确命中(=或者in)，这种场景本身就不会出现幻读，所以只会加行记录锁。

## 快照读

session A会话会生成一个[94,96,97]的数组。这时候，session A一开始生成的事务数组就派上用场了，session A的事务数组是[94,96,97]，最小事务ID是94，最大事务ID是97，所以，当它遇到一行数据时，会先判断这行数据的版本号X：

- 如果X大于97，那么意味着这行数据，是在session A开始之后，才提交的，应该对session A不可见

- 如果X小于97，那么分两种情况：

- - 如果X在数组里面，比如X是96，那么意味着，当session A开始时，生成这个版本的数据的事务，还没提交，因此这行数据对Session A不可见
  - 如果X不在数组里面，比如X是95，那么意味着，当session A开始时，生成这个版本的数据的事务，已经提交，因此这行数据对Session A可见

简单的select操作(不包括 select … lock in share mode, select … for update)。

Read Committed隔离级别：每次select都生成一个快照读。因此会产生不可重复读

Read Repeatable隔离级别：**开启事务后第一个select语句才是快照读的地方，而不是一开启事务就快照读。**

## MVCC(多版本并发控制)

借助MVCC，数据库可以实现RC，RR等隔离级别，用户可以查看当前数据的前一个或者前几个历史版本。保证了ACID中的I-隔离性。

上述现象在数据库中大家经常看到，但是数据库到底是怎么实现的，深究的人就不多了。  其实原理很简单，数据库就是通过UNDO和MVCC来实现的。

#### 1、通过DB_ROLL_PT 回溯查找数据历史版本

- 首先InnoDB每一行数据还有一个DB_ROLL_PT的回滚指针，用于指向该行修改前的上一个历史版本  

![img](md\30.jpeg)

 当插入的是一条新数据时，记录上对应的回滚段指针为NULL

![img](md\31.jpeg)

 更新记录时，原记录将被放入到undo表空间中，并通过DB_ROLL_PT指向该记录。session2查询返回的未修改数据就是从这个undo中返回的。MySQL就是根据记录上的回滚段指针及事务ID判断记录是否可见，如果不可见继续按照DB_ROLL_PT继续回溯查找。

## 数据库锁粒度大会引发什么问题

![img](md\32.jpg)

![img](md\33.png)

- 对于`UPDATE、DELETE、INSERT`语句，**InnoDB**会**自动**给涉及数据集加排他锁（X)

  **MyISAM**在执行查询语句`SELECT`前，会**自动**给涉及的所有表加**读锁**，在执行更新操作（`UPDATE、DELETE、INSERT`等）前，会**自动**给涉及的表加**写锁**，这个过程并**不需要用户干预**

- 共享锁（S）：`SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE`。

- 排他锁（X）：`SELECT * FROM table_name WHERE ... FOR UPDATE`。

- 间隙锁  :SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE;

允许多个线程同时对想读的内容加锁,即共享锁或叫S锁),写的时候不*能*读

InnoDB实现的`Repeatable read`隔离级别配合GAP间隙锁已经避免了幻读！

- 乐观锁其实是一种思想，正如其名：认为不会锁定的情况下去更新数据，如果发现不对劲，才不更新(回滚)。在数据库中往往添加一个version字段来实现。
- 悲观锁用的就是数据库的行锁，认为数据库会发生并发冲突，直接上来就把数据锁住，其他事务不能修改，直至提交了当前事务

## RR级别下 幻读例子

Mysql官方给出的幻读解释是：只要在一个事务中，第二次select多出了row就算幻读。
1.a事务先select，b事务insert确实会加一个gap锁，但是如果b事务commit，这个gap锁就会释放（释放后a事务可以随意dml操作），
2.a事务再select出来的结果在MVCC下还和第一次select一样，
3.接着a事务不加条件地update，这个update会作用在所有行上（包括b事务新加的），
4.a事务再次select就会出现b事务中的新行，并且这个新行已经被update修改了

原因是前面的UPDATE语句执行之后，会将当前记录上存储的事务信息更新为当前的事务，而当前事务所做的任何更新，对本事务所有SELECT查询都变的可见，因此最后输出的结果是UPDATE执行后更新的所有记录。

## 外连接

外连接：left join，right join

内连接：inner join（只显示满足条件的）

全连接：full join（满足的和不满足的都显示）

交叉连接：cross join（笛卡尔积）

## 表的范式的三大范式

第一范式（1NF）确保每列保持原子不可再分。
第二范式（2NF）属性完全依赖于主键：依赖于主键（联合主键）的一部分。
第三范式（3NF）属性不依赖于其它非主属性 ：依赖于非主键列。

## 查询前n名的sql语句

select a.s_id,a.c_id,a.s_score from score a 
where (select COUNT(1) from score b where b.c_id=a.c_id and b.s_score>=a.s_score)<=2 ORDER BY a.c_id

## limit 20000，10如何优化

SELECT id,title,content **FROM** items **WHERE** id IN (**SELECT** id **FROM** items **ORDER** **BY** id limit 900000, 10);  

不加order by会走全表

## 一个 SQL 执行的很慢的原因

怎么发现有问题的SQL?（通过MySQL慢查询日志对有效率问题的SQL进行监控）

通过explain查询和分析SQL的执行计划

1、大多数情况下很正常，偶尔很慢，则有如下原因

(1)、数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。

(2)、执行的时候，遇到锁，如表锁、行锁。

2、这条 SQL 语句一直执行的很慢，则有如下原因。

(1)、没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。

(2)、数据库选错了索引。

## explain的type类型


![](C:\Users\jimmiezeng\IdeaProjects\interview-review\md\82.png)

## SQL优化

第一优化你的sql和索引；

第二加缓存，memcached,redis；

第三以上都做了后，还是慢，就做主从复制，读写分离

第四如果以上都做了，那就先做垂直拆分，其实就是根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统；

第五才是水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key,为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表；

## 数据库分区和分表的区别

数据库分区：将大表进行分区，不同分区可以放置在不同存储设备上，这些分区在逻辑上组成一个大表，对客户端透明

1. 分区方式和水平切片是类似的，分区方式也和水平切片方式类似，如范围切片，取模切片等
2. 数据库分区是数据库自身的特性，切片则是外部强制手段控制完成的
3. 数据库分区无法将分区跨库，更不能跨数据库服务器，但能保存在不同数据文件从而放置在不同存储设备上
4. 数据库分区是数据库的特性，数据完整性、一致性等实现起来很方便，这一切都是数据库自身保证的

## 读写分离

主从复制原理：主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。

## 分库分表后的缺点

1、引入聚合函数的二次汇总

2、排序问题

## MySQL的delete,drop与truncate区别？

drop	表级的删除；
truncate	清空表；
delete	配合where删除数据；

## MySQL中varchar与char的区别以及varchar(50)中的50代表的涵义

#### (1)、varchar与char的区别

char是一种固定长度的类型，varchar则是一种可变长度的类型

#### (2)、varchar(50)中50的涵义

最多存放50个字符，varchar(50)和(200)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计算col长度(memory引擎也一样)

#### (3)、int（20）中20的涵义

是指显示字符的长度
但要加参数的，最大为255，比如它是记录行数的id,插入10笔资料，它就显示00000000001 ~~~00000000010，当字符的位数超过11,它也只显示11位，如果你没有加那个让它未满11位就前面加0的参数，它不会在前面加0
20表示最大显示宽度为20，但仍占4字节存储，存储范围不变；

## 有多少种日志?

错误日志：记录出错信息，也记录一些警告信息或者正确的信息。
查询日志：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。
二进制日志：记录对数据库执行更改的所有操作。
慢查询日志：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。
事务日志：

## 存储过程和触发器

存储过程：类似创建一个方法，带有参数，储存多条sql语句，在sql中调用。

触发器：创建一个事件在指定的“频率”，当“增删改”的“之前或之后”去执行。

# Redis

## 什么是Redis？

Redis本质上是一个Key-Value类型的内存数据库,因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。

## Redis为什么这么快？

- **纯内存操作**
- **单线程**
- **高效的数据结构**
- **合理的数据编码**
- **其他方面的优化**

## Redis多线程的设计

Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。之所以这么设计是不想因为多线程而变得复杂，需要去控制 key、lua（一种轻量级脚本语言）、事务，LPUSH/LPOP（redis语法：将一个或多个值插入到列表头部（左边）、移出并获取列表的第一个元素(左边)） 等等的并发问题。

## Redis相比memcached有哪些优势?

(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型
(2) redis的速度比memcached快很多
(3) redis可以持久化其数据

## Redis和mongoDB区别？

(1)mongoDb文档型数据数据库，可以存储海量数据

(2)redis使用纯内存操作，速度更好；mongoDB也可以将热点数据映射到内存；

(3)都支持事务

## Redis支持哪几种数据类型？ 

#### 3.1 字符串(string)

> 字符串编码有三个：int、raw、embstr。

##### 3.1.1 int

> 当string对象的值全部是数字，就会使用int编码。

```
127.0.0.1:6379> set number 123455
OK
127.0.0.1:6379> object encoding number
"int"
```

##### 3.1.2 embstr

> 字符串或浮点数长度小于等于39字节，就会使用embstr编码方式来存储，embstr存储内存一般很小，所以redis一次性分配且内存连续(效率高)。

```
127.0.0.1:6379> set shortStr "suwe suwe suwe"
OK
127.0.0.1:6379> object encoding shortStr
"embstr"
```

##### 3.1.2 raw

> 当一个字符串或浮点数长度大于39字节，就使用SDS来保存，编码为raw，由于不确定值的字节大小，所以键和值各分配各的，所以就分配两次内存(回收也是两次)，同理它一定不是内存连续的。

```
127.0.0.1:6379> set longStr "hello everyone, we dont need to sleep around to go aheard! do you think?"
OK
127.0.0.1:6379> object encoding longStr
"raw"
```

##### 3.1.3 编码转换

> 前面说过，Redis会自动对编码进行转换来适应和优化数据的存储。

int->raw

> 条件：数字对象进行append字母，就会发生转换。

```
127.0.0.1:6379> object encoding number
"int"
127.0.0.1:6379> append number " is a lucky number"
(integer) 24
127.0.0.1:6379> object encoding number
"raw"
```

embstr->raw

> 条件：对embstr进行修改，redis会先将其转换成raw，然后才进行修改。所以embstr实际上是只读性质的。

```
127.0.0.1:6379> object encoding shortStr
"embstr"
127.0.0.1:6379> append shortStr "(hhh"
(integer) 18
127.0.0.1:6379> object encoding shortStr
"raw"
```

#### 3.2 列表(list)

> 列表对象编码可以是：ziplist或linkedlist。

1. `ziplist`压缩列表不知道大家还记得不，就是`zlbytes zltail zllen entry1 entry2 ..end`结构,`entry节点`里有`pre-length、encoding、content`属性，忘记的可以返回去看下。
2. `linkedlist`,类似双向链表，也是上一章的知识。

##### 3.2.1 编码转换

ziplist->linkedlist

> 条件：列表对象的所有字符串元素的长度大于等于64字节 & 列表元素数大于等于512. 反之，小于64和小于512会使用ziplist而不是用linkedlist。

> 这个阈值是可以修改的，修改选项：`list-max-ziplist-value`和`list-max-ziplist-entriess```

#### 3.3 哈希(hash)

> 哈希对象的编码有:ziplist和hashtable

##### 3.3.1 编码转换

ziplist->hashtable

> 条件：哈希对象所有键和值字符串长度大于等于64字节 & 键值对数量大于等于512

> 这个阈值也是可以修改的，修改选项：`hash-max-ziplist-value`和`hash-max-ziplist-entriess```

#### 3.4. 集合(set)

> 集合对象的编码有：intset和hashtable

##### 3.4.1 intset

1. 集合对象所有元素都是整数
2. 集合对象元素数不超过512个

##### 3.4.2 编码转换

intset->hashtable

> 条件：元素不都是整数 & 元素数大于等于512

#### 3.5. 有序集合(zset)

> 有序集合用到的编码：ziplist和skiplist

大家可能很好奇阿，ziplist的entry中只有属性content可以存放数据，集合也是`key-value`形式，那怎么存储呢?

> 第一个节点保存key、第二个节点保存value 以此类推...

##### 3.5.1 为什么要用这两个编码

1. 如果只用ziplist来实现，无法做到元素的排序，不支持范围查找，能做到元素的快速查找。
2. 如果只用skiplist来实现，无法做到快速查找，但能做到元素排序、范围操作。

##### 3.5.2 编码转换

ziplist->skiplist

> 条件：有序集合元素数 >= 128 & 含有元素的长度 >= 64

> 这个阈值也是可以修改的，修改选项：`zset-max-ziplist-value`和`zset-max-ziplist-entriess`

## Redis有哪几种数据淘汰策略？ 

noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）
allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
allkeys-random: 回收随机的键使得新添加的数据有空间存放。
volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。

## 一个字符串类型的值能存储最大容量是多少**？** 

512M

## 为什么Redis需要把所有数据放到内存中 

Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。
所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。

## MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？ 

redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。 

## **Redis**有哪些适合的场景**？**

（1）会话缓存（Session Cache）
（2）全页缓存（FPC）
（3）消息队列
Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。
（4）排行榜/计数器
（5）发布/订阅
最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！

## 普通哈希

先对key进行哈希。得到哈希结果在取模。然后根据取模结果，去对应的服务器上，找到这个key对应的value。

缺点：扩容后映射关系大量失效。

## 哈希一致性

在0-最大正整数 的一个环中，将key的哈希结果放到环中，在顺时针的第一个服务器存放数据。

缺点：要保证服务器节点均匀分布在哈希环上

## 哈希槽

一共有16384个槽，每台服务器分管其中的一部分，插入一个数据的时候，将key的哈希结果对16384取余，确定将数据放到哪个槽里面

当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；

## 怎么测试Redis的连通性？

ping

## **Redis**事务相关的命令有哪几个**？**

MULTI(开启事务)EXEC(提交)DISCARD(回滚) 

## **Redis key**的过期时间和永久有效分别怎么设置？

expire persist

## **Redis**如何做内存优化？

尽可能使用散列表（hashes），hashes使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。

## **Redis**回收进程如何工作的？

一个客户端运行了新的命令，添加了新的数据。
Redi检查内存使用情况，如果大于maxmemory的限制, 则根据设定好的策略进行回收。
一个新的命令被执行，等等。

## 缓存雪崩和缓存穿透问题解决方案

### 缓存雪崩

简介：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。
解决：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。


### 缓存穿透

简介：一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。
解决办法： 

如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

双缓存机制：设置一级缓存和二级缓存，一级缓存过期时间短，二级缓存过期时间长或者不过期，一级缓存失效后访问二级缓存，同时刷新一级缓存和二级缓存。

![img](md\34.webp)

## 缓存一致性

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，**先更新数据库，然后再更新缓存**。**通过canal读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。**

##### 假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作

采用异步延时删除策略，或者是查完数据库再检测一次缓存是否有数据

#### 先更新数据库，再更新缓存

一、A更B更 ABBA

二、多写场景浪费性能

### 先删缓存，再更新数据库

A查B更 BAAB

### 先更新数据库，再删缓存

A查B更  ABBA （概率低，查的速度比写的速度快很多）

## 缓存预热

NGINX流量统计->流量重现

## 快照（snapshotting）持久化（RDB）

Redis可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。

## AOF（append-only file）持久化

开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。

## redis发布订阅模式

多个客户端sub订阅频道，一个客户端往频道发送信息。

## redis如何实现排行榜？

zadd list A score;

zrevrange list 0 -1 with scores;

zincrby list score A;

## 是否使用过Redis集群，集群的原理是什么？

Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。
Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。



